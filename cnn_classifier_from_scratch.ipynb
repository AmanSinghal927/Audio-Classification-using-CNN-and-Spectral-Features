{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e72660b",
      "metadata": {
        "id": "9e72660b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "# Sklearn \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# TensorFlow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d9e139a",
      "metadata": {
        "id": "1d9e139a"
      },
      "outputs": [],
      "source": [
        "import numpy as npimage_path_colorbar\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f9e7cf",
      "metadata": {
        "id": "c1f9e7cf"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a79cd8",
      "metadata": {
        "id": "29a79cd8"
      },
      "source": [
        "### Reading the 2021 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6c4566",
      "metadata": {
        "id": "fb6c4566",
        "outputId": "f1f4feec-ddb8-4c22-a589-d72dd4b92779"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
              "       'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'Unique Item ID', 'Title',\n",
              "       'CallerId', 'Item created date', 'transcription', 'state', 'tags',\n",
              "       'Recording audio link', 'Format', 'Gender', 'Checksum',\n",
              "       'Accept/Noisy label', 'file_name'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_xls = \"/Users/divya/Desktop/GV_work_dir/data_excel\"\n",
        "xls_2021_name = \"2021_2K.xlsx\"\n",
        "xls_2021 = pd.read_excel(os.path.join(path_xls,xls_2021_name))\n",
        "xls_2021.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bd1a20",
      "metadata": {
        "id": "87bd1a20"
      },
      "outputs": [],
      "source": [
        "xls_2021[\"file_name\"] = xls_2021[\"Recording audio link\"].apply(lambda x:x.split(\"/\")[-1])\n",
        "xls_2021[\"file_name\"] = xls_2021[\"file_name\"].apply(lambda x:x.split(\".\")[0])\n",
        "xls_2021_name = \"2021_2K.xlsx\"\n",
        "xls_2021.to_excel(os.path.join(path_xls,xls_2021_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f12e95f2",
      "metadata": {
        "id": "f12e95f2"
      },
      "source": [
        "### Generating Spectrogram features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845685ae",
      "metadata": {
        "id": "845685ae"
      },
      "source": [
        "#### Function to generate Spectrogram features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56783a59",
      "metadata": {
        "id": "56783a59"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram_features(x, sr,label_info,_id):\n",
        "# Extract the audio spectrogram\n",
        "    try:\n",
        "        image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/{}/simple/\".format(label_info)    \n",
        "        S = librosa.feature.melspectrogram(x, sr=sr, n_mels=128,fmax=8000)\n",
        "#         plt.figure(figsize=(14,5))\n",
        "#         librosa.display.specshow(S_dB, x_axis='time',y_axis='mel', sr=sr,fmax=8000)\n",
        "        # plt.colorbar()\n",
        "#         plt.savefig(image_path_colorbar+_id,pad_inches = 0,bbox_inches='tight')\n",
        "        plt.figure(figsize=(8, 5),frameon=False)\n",
        "        plt.axis(\"off\")\n",
        "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "        librosa.display.specshow(S_dB, sr=sr,fmax=8000)\n",
        "        # plt.plot()\n",
        "        plt.savefig(image_path_simple+_id,pad_inches = 0,bbox_inches='tight')\n",
        "    except Exception as e:\n",
        "        print(\"Error: {}\".format(str(e)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d999e78",
      "metadata": {
        "id": "3d999e78"
      },
      "source": [
        "#### Creating Directories to save the Spectrogram images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479cf9eb",
      "metadata": {
        "id": "479cf9eb"
      },
      "outputs": [],
      "source": [
        "noisy_str = \"noisy\"\n",
        "image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/{}/simple/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_simple):\n",
        "    os.makedirs(image_path_simple)\n",
        "    \n",
        "    \n",
        "noisy_str = \"clean\"\n",
        "image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/{}/simple/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_simple):\n",
        "    os.makedirs(image_path_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9848a8f2",
      "metadata": {
        "id": "9848a8f2"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b8e71e2",
      "metadata": {
        "id": "1b8e71e2"
      },
      "outputs": [],
      "source": [
        "xls_2021 = xls_2021.iloc[0:10,:].copy() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7bd049",
      "metadata": {
        "scrolled": true,
        "id": "6d7bd049"
      },
      "outputs": [],
      "source": [
        "base_audio_path = \"/Users/divya/Desktop/GV_work_dir/\"\n",
        "folder_1 = \"wave_files_clean_data\"\n",
        "folder_2 = \"wave_files_noisy_data\"\n",
        "folder_3 = \"wave_files_noisy_data 2\"\n",
        "folder_4 = \"wave_files_noisy_data 3\"\n",
        "\n",
        "\n",
        "folder_list = [folder_1, folder_2, folder_3, folder_4]\n",
        "duration_dict = {}\n",
        "found_list = []\n",
        "\n",
        "for _id in tqdm.tqdm(xls_2021[\"file_name\"]):\n",
        "    for i in folder_list:\n",
        "        try:\n",
        "            if \"clean\" in i:\n",
        "                label_info = \"clean\"\n",
        "            else:\n",
        "                label_info = \"noisy\"\n",
        "                \n",
        "            image_path_colorbar = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/{}/colorbar/\".format(label_info)     \n",
        "            if not os.path.exists(os.path.join(image_path_colorbar,_id+\".png\")):\n",
        "                filename_wave = base_audio_path+i+\"/\"+_id+\".wav\"\n",
        "                x,sr = librosa.load(filename_wave, sr=44100)   \n",
        "                get_spectrogram_features(x, sr,label_info,_id)\n",
        "                break\n",
        "            \n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b190fe70",
      "metadata": {
        "id": "b190fe70"
      },
      "source": [
        "## Previous CNN Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd53865",
      "metadata": {
        "id": "9dd53865"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('./model_noisy.keras')\n",
        "img_path = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd7d840",
      "metadata": {
        "id": "3bd7d840",
        "outputId": "49135b9e-f8f8-413f-9ba7-50fcdae49004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 838 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator()\n",
        "test_Data = datagen.flow_from_directory(img_path,target_size=(224, 224), \n",
        "                                        class_mode='binary',batch_size=40,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550ab907",
      "metadata": {
        "id": "550ab907"
      },
      "outputs": [],
      "source": [
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2adf30bd",
      "metadata": {
        "id": "2adf30bd",
        "outputId": "d7180b13-f787-4b38-8b47-912b79c919f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 7s 304ms/step\n",
            "Run time is  10.448875\n"
          ]
        }
      ],
      "source": [
        "start = dt.datetime.now()\n",
        "Y_pred = model.predict(test_Data,verbose = 1,batch_size = 40)\n",
        "end = dt.datetime.now()\n",
        "diff = end-start\n",
        "diff_sec = diff.total_seconds()\n",
        "print (\"Run time is \", diff_sec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c3a014",
      "metadata": {
        "id": "38c3a014",
        "outputId": "60b81bc8-a25e-4fdd-cc2e-25a9f31a9711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[142 212]\n",
            " [  2 482]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.40      0.57       354\n",
            "           1       0.69      1.00      0.82       484\n",
            "\n",
            "    accuracy                           0.74       838\n",
            "   macro avg       0.84      0.70      0.69       838\n",
            "weighted avg       0.82      0.74      0.71       838\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.where(Y_pred < 0.5, 1,0)\n",
        "print(confusion_matrix(test_Data.classes, y_pred))\n",
        "print(classification_report(test_Data.classes, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857514eb",
      "metadata": {
        "id": "857514eb",
        "outputId": "29834d99-9850-4209-b52b-c3bbb876474f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[281  73]\n",
            " [ 21 463]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86       354\n",
            "           1       0.86      0.96      0.91       484\n",
            "\n",
            "    accuracy                           0.89       838\n",
            "   macro avg       0.90      0.88      0.88       838\n",
            "weighted avg       0.89      0.89      0.89       838\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.where(Y_pred < 0.15, 1,0)\n",
        "print(confusion_matrix(test_Data.classes, y_pred))\n",
        "print(classification_report(test_Data.classes, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee51ced",
      "metadata": {
        "id": "2ee51ced"
      },
      "source": [
        "## 2020 data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da32eb3",
      "metadata": {
        "id": "8da32eb3"
      },
      "outputs": [],
      "source": [
        "path_xls = \"/Users/divya/Desktop/GV_work_dir/data_excel\"\n",
        "xls_2020_name = \"20K_files.xlsx\"\n",
        "xls_2020 = pd.read_excel(os.path.join(path_xls,xls_2020_name))\n",
        "\n",
        "xls_2020[\"file_name\"] = xls_2020[\"Recording audio link\"].apply(lambda x:x.split(\"/\")[-1])\n",
        "xls_2020[\"file_name\"] = xls_2020[\"file_name\"].apply(lambda x:x.split(\".\")[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff741373",
      "metadata": {
        "id": "ff741373",
        "outputId": "d563e203-5b14-4644-ab56-78ba4fd63b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'Instance name', 'Unique Item ID', 'Title', 'CallerId',\n",
            "       'State', 'Block', 'District', 'Item created date', 'transcription',\n",
            "       'state', 'tags', 'Recording audio link', 'Total listening duration',\n",
            "       'Item duration', 'published date', 'Format', 'Gender', 'Checksum',\n",
            "       'Accept/Noisy label', 'file_name'],\n",
            "      dtype='object')\n",
            "(20000, 21)\n"
          ]
        }
      ],
      "source": [
        "print (xls_2020.columns)\n",
        "print (xls_2020.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f850508",
      "metadata": {
        "id": "3f850508"
      },
      "source": [
        "#### Creating Directories to save the Spectrogram images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03619471",
      "metadata": {
        "id": "03619471"
      },
      "outputs": [],
      "source": [
        "noisy_str = \"noisy\"\n",
        "image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2020/{}/simple/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_simple):\n",
        "    os.makedirs(image_path_simple)\n",
        "    \n",
        "    \n",
        "noisy_str = \"clean\"\n",
        "image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2020/{}/simple/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_simple):\n",
        "    os.makedirs(image_path_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340783a5",
      "metadata": {
        "id": "340783a5"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3cf466",
      "metadata": {
        "id": "4e3cf466"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram_features(x, sr,label_info,_id,image_path_simple):\n",
        "# Extract the audio spectrogram\n",
        "    try:\n",
        "        S = librosa.feature.melspectrogram(x, sr=sr, n_mels=128,fmax=8000)\n",
        "        plt.figure(figsize=(8, 5),frameon=False)\n",
        "        plt.axis(\"off\")\n",
        "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "        librosa.display.specshow(S_dB, sr=sr,fmax=8000)\n",
        "        plt.plot()\n",
        "        plt.savefig(image_path_simple+_id,pad_inches = 0,bbox_inches='tight')\n",
        "    except Exception as e:\n",
        "        print(\"Error: {}\".format(str(e)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdc6161",
      "metadata": {
        "scrolled": true,
        "id": "0bdc6161"
      },
      "outputs": [],
      "source": [
        "base_audio_path = \"/Users/divya/Desktop/GV_work_dir/2020_raw_wave_files/\"\n",
        "folder_1 = \"wave_files_clean_data\"\n",
        "folder_2 = \"wave_files_noisy_data\"\n",
        "\n",
        "folder_list = [folder_1, folder_2]\n",
        "duration_dict = {}\n",
        "found_list = []\n",
        "\n",
        "for _id in tqdm.tqdm(xls_2020[\"file_name\"]):\n",
        "    for i in folder_list:\n",
        "        try:\n",
        "            if \"clean\" in i:\n",
        "                label_info = \"clean\"\n",
        "            else:\n",
        "                label_info = \"noisy\"\n",
        "                \n",
        "            image_path_simple = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2020/{}/simple/\".format(label_info)     \n",
        "            if not os.path.exists(os.path.join(image_path_simple,_id+\".png\")):\n",
        "                filename_wave = base_audio_path+i+\"/\"+_id+\".wav\"\n",
        "                x,sr = librosa.load(filename_wave, sr=44100)   \n",
        "                get_spectrogram_features(x, sr,label_info,_id,image_path_simple)\n",
        "                break\n",
        "            \n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c88e28e",
      "metadata": {
        "id": "7c88e28e"
      },
      "source": [
        "## CNN model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb52562",
      "metadata": {
        "id": "9cb52562"
      },
      "outputs": [],
      "source": [
        "num_rows = 224\n",
        "num_columns = 224\n",
        "num_channels = 3\n",
        "num_labels = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be2a808",
      "metadata": {
        "scrolled": true,
        "id": "0be2a808",
        "outputId": "3bdc5ff4-fc77-4606-e143-2b02c7fcaf62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 223, 223, 16)      208       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 111, 111, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 111, 111, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 110, 110, 32)      2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 55, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 55, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 54, 54, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 27, 27, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 27, 27, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 43,569\n",
            "Trainable params: 43,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Construct model\n",
        "model_AA_2 = Sequential() # AA - After Augmentation 2- Validation increased\n",
        "model_AA_2.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model_AA_2.add(MaxPooling2D(pool_size=2))\n",
        "model_AA_2.add(Dropout(0.2))\n",
        "\n",
        "model_AA_2.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model_AA_2.add(MaxPooling2D(pool_size=2))\n",
        "model_AA_2.add(Dropout(0.2))\n",
        "\n",
        "model_AA_2.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_AA_2.add(MaxPooling2D(pool_size=2))\n",
        "model_AA_2.add(Dropout(0.2))\n",
        "\n",
        "model_AA_2.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model_AA_2.add(MaxPooling2D(pool_size=2))\n",
        "model_AA_2.add(Dropout(0.2))\n",
        "model_AA_2.add(GlobalAveragePooling2D())\n",
        "\n",
        "model_AA_2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_AA_2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', # Loss\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Display model architecture summary\n",
        "model_AA_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df5c0074",
      "metadata": {
        "id": "df5c0074"
      },
      "source": [
        "### Train and Validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bac0723",
      "metadata": {
        "id": "4bac0723"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "test_data = \"/Users/divya/Desktop/GV_work_dir/test_data/2021_half.xlsx\"\n",
        "test_data_excel = pd.read_excel(test_data)\n",
        "test_file_png = [str(x)+\".png\" for x in test_data_excel[\"file_name\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570ab9c1",
      "metadata": {
        "id": "570ab9c1"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "base_path_2021 = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021\"\n",
        "clean_files_2021 = glob.glob(base_path_2021+'/clean/simple/*.png')\n",
        "noisy_files_2021 = glob.glob(base_path_2021+'/noisy/simple/*.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0944adf1",
      "metadata": {
        "id": "0944adf1"
      },
      "outputs": [],
      "source": [
        "clean_files_2021 = [x.split(\"/\")[-1] for x in clean_files_2021]\n",
        "noisy_files_2021 = [x.split(\"/\")[-1] for x in noisy_files_2021]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448b2d54",
      "metadata": {
        "id": "448b2d54"
      },
      "outputs": [],
      "source": [
        "noisy_str = \"noisy\"\n",
        "image_path_val_noisy = \"/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/val_set/{}/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_val_noisy):\n",
        "    os.makedirs(image_path_val_noisy)\n",
        "\n",
        "    \n",
        "    \n",
        "noisy_str = \"clean\"\n",
        "image_path_val_clean = \"Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/val_set/{}/\".format(noisy_str)\n",
        "\n",
        "if not os.path.exists(image_path_val_clean):\n",
        "    os.makedirs(image_path_val_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f52d322",
      "metadata": {
        "id": "7f52d322",
        "outputId": "b2118f9f-80c9-4ece-dea1-140fc143026f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/val_set/clean/'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_path_val_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc87a15",
      "metadata": {
        "id": "cdc87a15"
      },
      "outputs": [],
      "source": [
        "#Moving clean files to validation folder\n",
        "for f in clean_files_2021:\n",
        "    if f in test_file_png:\n",
        "        continue\n",
        "    else:\n",
        "        shutil.move(base_path_2021+\"/clean/simple/\"+f, image_path_val_clean)\n",
        "\n",
        "# Moving noisy files to validation folder\n",
        "for f in noisy_files_2021:\n",
        "    if f in test_file_png:\n",
        "        continue\n",
        "    else:\n",
        "        shutil.move(base_path_2021+\"/noisy/simple/\"+f, image_path_val_noisy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d711a66",
      "metadata": {
        "id": "1d711a66"
      },
      "source": [
        "#### Retraining starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb7cb9b",
      "metadata": {
        "id": "8eb7cb9b",
        "outputId": "bc662828-4345-4e41-8903-888eb2cdcb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 19991 images belonging to 2 classes.\n",
            "Found 848 images belonging to 2 classes.\n",
            "Found 838 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator()\n",
        "train_it = datagen.flow_from_directory('/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2020/',target_size=(224, 224), class_mode='binary',batch_size=40)\n",
        "val_it = datagen.flow_from_directory('/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/val_set',target_size=(224, 224), class_mode='binary',batch_size=40)\n",
        "test_it = datagen.flow_from_directory('/Users/divya/Desktop/GV_work_dir/CNN model/spectrogram_data/2021/',target_size=(224, 224), class_mode='binary',batch_size=40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687c4cc3",
      "metadata": {
        "scrolled": true,
        "id": "687c4cc3",
        "outputId": "574d60cd-0d38-4d40-e33d-938777e5aa10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.4140 - binary_accuracy: 0.8207WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
            "400/400 [==============================] - 500s 1s/step - loss: 0.4140 - binary_accuracy: 0.8207 - val_loss: 0.6122 - val_binary_accuracy: 0.6781\n",
            "\n",
            "Epoch 00001: binary_accuracy improved from -inf to 0.82071, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 511s 1s/step - loss: 0.3525 - binary_accuracy: 0.8442\n",
            "\n",
            "Epoch 00002: binary_accuracy improved from 0.82071 to 0.84416, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 479s 1s/step - loss: 0.3237 - binary_accuracy: 0.8620\n",
            "\n",
            "Epoch 00003: binary_accuracy improved from 0.84416 to 0.86200, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 435s 1s/step - loss: 0.3065 - binary_accuracy: 0.8744\n",
            "\n",
            "Epoch 00004: binary_accuracy improved from 0.86200 to 0.87443, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 446s 1s/step - loss: 0.2817 - binary_accuracy: 0.8848\n",
            "\n",
            "Epoch 00005: binary_accuracy improved from 0.87443 to 0.88475, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 471s 1s/step - loss: 0.2690 - binary_accuracy: 0.8888\n",
            "\n",
            "Epoch 00006: binary_accuracy improved from 0.88475 to 0.88881, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 534s 1s/step - loss: 0.2500 - binary_accuracy: 0.9011\n",
            "\n",
            "Epoch 00007: binary_accuracy improved from 0.88881 to 0.90107, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 530s 1s/step - loss: 0.2520 - binary_accuracy: 0.8983\n",
            "\n",
            "Epoch 00008: binary_accuracy did not improve from 0.90107\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 537s 1s/step - loss: 0.2378 - binary_accuracy: 0.9049\n",
            "\n",
            "Epoch 00009: binary_accuracy improved from 0.90107 to 0.90488, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 533s 1s/step - loss: 0.2332 - binary_accuracy: 0.9056\n",
            "\n",
            "Epoch 00010: binary_accuracy improved from 0.90488 to 0.90563, saving model to /Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras\n",
            "Training completed in time:  1:23:47.034444\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "num_batch_size = 40\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/Users/divya/Desktop/GV_work_dir/CNN model/model_noisy_2.keras',\n",
        "                               verbose=1, save_best_only=True, monitor = \"binary_accuracy\")\n",
        "\n",
        "start = datetime.now()\n",
        "hist = model_AA_2.fit(train_it,steps_per_epoch=400,epochs = 10, validation_data=val_it,validation_steps= 40,callbacks=[checkpointer], verbose=1)\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02481e60",
      "metadata": {
        "id": "02481e60"
      },
      "source": [
        "#### New Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19cf45c0",
      "metadata": {
        "id": "19cf45c0",
        "outputId": "ad94421c-1d90-4e47-a7d9-efe3e849b61a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 6s 294ms/step\n"
          ]
        }
      ],
      "source": [
        "Y_pred = model_AA_2.predict(test_it,verbose = 1,batch_size = 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d4e378",
      "metadata": {
        "id": "27d4e378",
        "outputId": "efdd1fd1-4e0f-4a3b-ac17-1e0e823be0d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[177 177]\n",
            " [256 228]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.50      0.45       354\n",
            "           1       0.56      0.47      0.51       484\n",
            "\n",
            "    accuracy                           0.48       838\n",
            "   macro avg       0.49      0.49      0.48       838\n",
            "weighted avg       0.50      0.48      0.49       838\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.where(Y_pred < 0.5, 1,0)\n",
        "print(confusion_matrix(test_it.classes, y_pred))\n",
        "print(classification_report(test_it.classes, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e662e9",
      "metadata": {
        "id": "c2e662e9"
      },
      "outputs": [],
      "source": [
        "model_AA_2.save('./data/model_AA_new.keras')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}